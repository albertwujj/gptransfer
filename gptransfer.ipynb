{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gptransfer2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertwujj/gptransfer/blob/master/gptransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ED518AlnbHEb",
        "colab_type": "code",
        "outputId": "449cab85-4bf1-4a31-ca54-2b94dd23eceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# I put the final embedding output through a fully-connected layer and train on binary cross-entropy,\n",
        "# and freeze the earlier layers of the decoder and add regularization.\n",
        "\n",
        "# I haven't finished experimenting with this particular fine-tuning method yet, will add comments\n",
        "\n",
        "from os.path import join\n",
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"\n",
        "drive.mount(ROOT, force_remount=True)\n",
        "\n",
        "PROJ = \"My Drive/ColabExperiments/\"\n",
        "PROJECT_PATH = join(ROOT, PROJ)\n",
        "%cd \"{PROJECT_PATH}\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/ColabExperiments\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tjHg2j9jkpVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from importlib.machinery import SourceFileLoader\n",
        "model = SourceFileLoader('model', 'gpt-2/src/model.py').load_module()\n",
        "encoder = SourceFileLoader('encoder', 'gpt-2/src/encoder.py').load_module()\n",
        "sample = SourceFileLoader('sample', 'gpt-2/src/sample.py').load_module()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GkMT9lW_ICKA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import sys\n",
        "np.set_printoptions(precision=3,threshold=sys.maxsize)\n",
        "import gc\n",
        "\n",
        "from itertools import islice\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "seed = None\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yzC4ZoGYYOjw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prepare data cell\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from encoder import Encoder\n",
        "\n",
        "def read_amazon_kaggle(filename, lines=None):\n",
        "    with open(filename) as f:\n",
        "        y_x = [(1 if line[9] == '2' else 0, line[10:].strip()) for line in f]\n",
        "        if lines:\n",
        "            y_x = random.sample(y_x, lines)\n",
        "        y, x = zip(*y_x)\n",
        "        return x, y\n",
        "    \n",
        "def read_toxicity(filename, lines=None):\n",
        "    with open(filename, newline='') as f:\n",
        "        reader = csv.reader(f, delimiter=',', quotechar='\\\"')\n",
        "        next(reader)\n",
        "        y_x = [(float(row[1]), row[2].strip('\\\"')) for row in reader]\n",
        "        if lines:\n",
        "            y_x = random.sample(y_x, lines)\n",
        "        y, x = zip(*y_x)\n",
        "        return x, y\n",
        "    \n",
        "def get_encoder(model_name):\n",
        "    with open(os.path.join('gpt-2/models', model_name, 'encoder.json'), 'r') as f:\n",
        "        encoder = json.load(f)\n",
        "    with open(os.path.join('gpt-2/models', model_name, 'vocab.bpe'), 'r', encoding=\"utf-8\") as f:\n",
        "        bpe_data = f.read()\n",
        "    bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]\n",
        "    return Encoder(\n",
        "        encoder=encoder,\n",
        "        bpe_merges=bpe_merges,\n",
        "    )\n",
        "\n",
        "def encode(x, y, model_name='117M'):\n",
        "    enc = get_encoder(model_name)\n",
        "    xcode = []\n",
        "    for i, x in enumerate(x):\n",
        "        vec = enc.encode(x)\n",
        "        xcode.append(vec)\n",
        "    x = xcode\n",
        "    return zip(*sorted(zip(x, y), key = lambda t: len(t[0])))\n",
        "      \n",
        "def get_data(x_raw, y_raw):\n",
        "  \n",
        "    x_all, y_all = encode(x_raw, y_raw)\n",
        "    x_all, y_all = (np.asarray(x_all), np.asarray(y_all))\n",
        "    return x_all, y_all\n",
        "\n",
        "def mod_by_batchsize(x):\n",
        "    l = (len(x) // batch_size) * batch_size\n",
        "    x = x[:l]\n",
        "    return x\n",
        "    \n",
        "\n",
        "\n",
        "lines = 30000\n",
        "#x_raw, y_raw = read_toxicity('gptransfer/data/jigsaw_toxicity/train.csv')\n",
        "x_raw, y_raw = read_amazon_kaggle('gptransfer/data/amazonreviews/train.ft.txt', lines)\n",
        "x_all, y_all = get_data(x_raw, y_raw)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYYhzjFB3VGk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyper Param definition cell\n",
        "\n",
        "frozen_layers = 8 # how many GPT2 layers to not train (out of 12)\n",
        "all_dropout = False\n",
        "lr = 0.0001\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3y31vSJDdqbU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This cell contains all code copied from GPT2. Original GPT2 model with slight modifications.\n",
        "\n",
        "from model import shape_list, positions_for, norm, default_hparams, block, gelu, conv1d\n",
        "\n",
        "dropout_prob = None\n",
        "curr_layer = None\n",
        "\n",
        "    \n",
        "def mlp_dropout(x, scope, n_state, *, hparams):\n",
        "    with tf.variable_scope(scope):\n",
        "        nx = x.shape[-1].value\n",
        "        h = gelu(conv1d(x, 'c_fc', n_state))\n",
        "        if all_dropout and curr_layer > frozen_layers:\n",
        "            h = tf.nn.dropout(h, rate=dropout_prob)\n",
        "        h2 = conv1d(h, 'c_proj', nx)\n",
        "        if curr_layer > frozen_layers:\n",
        "            h2 = tf.nn.dropout(h2, rate=dropout_prob)\n",
        "        return h2\n",
        "    \n",
        "    \n",
        "model.mlp = mlp_dropout\n",
        "\n",
        "def custom_model(hparams, X, past=None, scope='model', reuse=False):\n",
        "    global dropout_prob, curr_layer\n",
        "    dropout_prob = tf.placeholder_with_default(0.0, shape=())\n",
        "    with tf.variable_scope(scope, reuse=reuse):\n",
        "        results = {}\n",
        "        batch, sequence = shape_list(X)\n",
        "\n",
        "        wpe = tf.get_variable('wpe', [hparams.n_ctx, hparams.n_embd],\n",
        "                             initializer=tf.random_normal_initializer(stddev=0.01))\n",
        "        wte = tf.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
        "                             initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "        past_length = 0 if past is None else tf.shape(past)[-2]\n",
        "        h = tf.gather(wte, X) + tf.gather(wpe, positions_for(X, past_length))\n",
        "        \n",
        "        # Transformer\n",
        "        presents = []\n",
        "        pasts = tf.unstack(past, axis=1) if past is not None else [None] * hparams.n_layer\n",
        "        assert len(pasts) == hparams.n_layer\n",
        "        for layer, past in enumerate(islice(pasts, hparams.n_layer)):\n",
        "            curr_layer=layer\n",
        "            h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n",
        "            if layer == frozen_layers:\n",
        "                h = tf.stop_gradient(h)\n",
        "            presents.append(present)\n",
        "        results['present'] = tf.stack(presents, axis=1)\n",
        "        h = norm(h, 'ln_f')\n",
        "\n",
        "        # Language model loss.  Do tokens <n predict token n?\n",
        "        h_flat = tf.reshape(h, [batch*sequence, hparams.n_embd])\n",
        "        logits = tf.matmul(h_flat, wte, transpose_b=True)\n",
        "        logits = tf.reshape(logits, [batch, sequence, hparams.n_vocab])\n",
        "        results['logits'] = logits\n",
        "\n",
        "        results['h'] = h\n",
        "        return results\n",
        " \n",
        "def small_model(hparams, X, **kwargs):\n",
        "    hparams.n_layer = 5\n",
        "    return custom_model(hparams, X, **kwargs)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0rNROgCylCWb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def load_model(model_name='117M'):\n",
        "    with open(os.path.join('gpt-2/models', model_name, 'hparams.json')) as f:\n",
        "        hparams = model.default_hparams()\n",
        "        hparams.override_from_dict(json.load(f))   \n",
        "        def step(hparams, tokens, past=None):\n",
        "            lm_output = custom_model(hparams=hparams, X=tokens, past=None, reuse=tf.AUTO_REUSE)\n",
        "            h = lm_output['h']\n",
        "            return {\n",
        "                'h': h\n",
        "            }\n",
        "        \n",
        "        X = tf.placeholder(tf.int32, [batch_size, None])\n",
        "        outputs = step(hparams, X) # (batch, sequence, embedding)\n",
        "        \n",
        "        saver = tf.train.Saver()\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join('gpt-2/models', model_name))\n",
        "        saver.restore(sess, ckpt)\n",
        "        \n",
        "    return X, outputs\n",
        "\n",
        "def add_binary_finetune(outputs):\n",
        "    with tf.variable_scope('binary_finetune'):\n",
        "        \n",
        "        final_embd = outputs['h'][:,-1,:]\n",
        "        w = tf.get_variable('w', (final_embd.shape[-1],), initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
        "        b = tf.get_variable('b', (final_embd.shape[0],), initializer=tf.constant_initializer(0))\n",
        "        sess.run(tf.variables_initializer([w,b]))\n",
        "        l2loss = tf.nn.l2_loss(w)\n",
        "        logits = tf.tensordot(final_embd,w, [[1],[0]], name='z') + b\n",
        "        ypred = tf.nn.sigmoid(logits)\n",
        "        \n",
        "        ytrue = tf.placeholder(tf.float32, (batch_size,))\n",
        "      \n",
        "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=ytrue, logits=logits) + l2loss * .02)\n",
        "        \n",
        "        global_step = tf.Variable(0, trainable=False)\n",
        "        starter_learning_rate = lr\n",
        "        learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
        "                                           800//batch_size, 0.95, staircase=False)\n",
        "        optim = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "        minimize = optim.minimize(loss)\n",
        "        sess.run(tf.variables_initializer(optim.variables() + [global_step]))\n",
        "        \n",
        "    return ytrue, ypred, minimize, optim\n",
        "\n",
        "\n",
        "def get_train_infer(X, outputs, ytrue, ypred, minimize):\n",
        "    \n",
        "    def train(dataX, labels):\n",
        "        for i in range(0, len(dataX), batch_size):\n",
        "            xfeed = pad_sequences(dataX[i:i+batch_size])\n",
        "            yfeed = labels[i:i+batch_size]\n",
        "            sess.run(minimize, feed_dict={X:xfeed, ytrue:yfeed, dropout_prob: 0.5})\n",
        "\n",
        "    def infer(dataX):\n",
        "        preds = []\n",
        "        for i in range(0, len(dataX), batch_size):\n",
        "            xfeed = pad_sequences(dataX[i:i+batch_size])\n",
        "            predbatch = sess.run(ypred, feed_dict={X: xfeed})\n",
        "            preds.append(predbatch)\n",
        "                \n",
        "        preds = np.concatenate(preds, axis=0)\n",
        "        return preds\n",
        "\n",
        "    return train, infer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNFMRQIA9s93",
        "colab_type": "code",
        "outputId": "2d7e4f73-0e79-4b8f-f2f8-f45bb9d03ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5630
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from tensorflow.contrib.memory_stats.python.ops.memory_stats_ops import MaxBytesInUse\n",
        "from sklearn.model_selection import KFold as KFold\n",
        "from itertools import product\n",
        "\n",
        "import multiprocess as mp # must spawn new process after clearing GPU mem\n",
        "\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "sess = None\n",
        "\n",
        "import pickle\n",
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "from numba import cuda\n",
        "from functools import reduce\n",
        "import sklearn\n",
        "\n",
        "def loadTrials(): \n",
        "    trials = pickle.load(open(\"gptransfer/results/trials.p\", \"rb\"))\n",
        "    # delete all 'running' jobs- jobs stopped in execution\n",
        "    trials._dynamic_trials = [t for t in trials._dynamic_trials if t['state'] != 1 and t['state'] != 3]\n",
        "    for i, t in enumerate(trials._dynamic_trials):\n",
        "        t['tid'] = i\n",
        "    trials._ids = set()\n",
        "    trials.refresh()\n",
        "    return trials\n",
        "\n",
        "def main():\n",
        "\n",
        "    space = {'all_dropout': False, 'lr': hp.loguniform('learning_rate', np.log(.00001), np.log(.001)),'frozen_offset':hp.randint('fo',3)}\n",
        "    trials = loadTrials()\n",
        "    \n",
        "    print(len(trials.trials))\n",
        "    with open('gptransfer/results/out', 'w', buffering=1) as out:\n",
        "        printout = lambda w: out.write(w + '\\n')\n",
        "\n",
        "        def objective(space):\n",
        "            print(f'trial number {len(trials.trials)}')\n",
        "            pickle.dump(trials, open('gptransfer/results/trials.p', 'wb'))\n",
        "            global all_dropout, lr, frozen_layers\n",
        "            all_dropout = space['all_dropout']\n",
        "            lr = space['lr']\n",
        "            frozen_offset = space['frozen_offset']\n",
        "            frozen_layers = 5 + frozen_offset\n",
        "            configs_string = reduce(lambda x,y:x+y,[f'{k} {v} ' for k, v in space.items()])\n",
        "            print(configs_string)\n",
        "            \n",
        "            kf = KFold(n_splits=3,random_state=None, shuffle=True)\n",
        "            accuracies = []\n",
        "            for train_index, val_index in islice(kf.split(x_all, y_all), 2):\n",
        "                x_train, y_train, x_val, y_val = [mod_by_batchsize(arr[inds]) for inds, arr in product([train_index, val_index], [x_all, y_all])]\n",
        "                \n",
        "                def run_fold(acc):\n",
        "                    with tf.device('/device:GPU:0') as dev, tf.Session(graph=tf.get_default_graph(),\n",
        "                                                                       config=tf.ConfigProto(allow_soft_placement=True)) as sessl:\n",
        "                        global sess\n",
        "                        sess = sessl\n",
        "                        max_bytes_in_use = MaxBytesInUse()\n",
        "\n",
        "                        X, outputs = load_model()\n",
        "                        ytrue, ypred, minimize, optim = add_binary_finetune(outputs)\n",
        "                        train, infer = get_train_infer(X, outputs, ytrue, ypred, minimize)\n",
        "\n",
        "                        eval_batchsize = 100000000000\n",
        "                        eval_batchsize = (eval_batchsize//batch_size) * batch_size\n",
        "                        start = timer()\n",
        "\n",
        "                        for i in range(0, x_train.shape[0], eval_batchsize):\n",
        "\n",
        "                            end = min(x_train.shape[0], i+eval_batchsize)\n",
        "                            x_train_b = x_train[i:end]\n",
        "                            y_train_b = y_train[i:end]\n",
        "                            train(x_train_b, y_train_b)\n",
        "\n",
        "                            pred_val = infer(x_val)\n",
        "                            corrects = np.count_nonzero(np.sign(y_val - .5) == \n",
        "                                                        np.sign(pred_val - .5)) / y_val.shape[0]\n",
        "\n",
        "                            gb_used = sess.run(max_bytes_in_use) / 1e9\n",
        "                            \n",
        "                            printout(f'GPU GB used {i//eval_batchsize}: {gb_used:.2f}')\n",
        "                            print(f'GPU GB used {i//eval_batchsize}: {gb_used:.2f}')\n",
        "                            print(f'elapsed minutes {i//eval_batchsize}: {(timer() - start)//60}')\n",
        "\n",
        "                        accuracy = np.count_nonzero(np.sign(y_val - .5) == np.sign(pred_val - .5)) / y_val.shape[0] if type(y_val.tolist()[0]) == int else sklearn.metrics.log_loss(y_val, pred_val)\n",
        "                        print('Fold Complete')\n",
        "                        print(f'Accuracy: {accuracy}')\n",
        "                        acc.value = accuracy\n",
        "                        cuda.select_device(0)\n",
        "                        cuda.close()\n",
        "                \n",
        "                acc = mp.Value('f',0.0)\n",
        "                p = mp.Process(target=run_fold, args=(acc,))\n",
        "                \n",
        "                p.start()\n",
        "                p.join()\n",
        "                if 0 and acc.value < .3: # too bad, don't do next\n",
        "                    return {'loss': -acc.value, 'status': STATUS_OK}\n",
        "                accuracies.append(acc.value)\n",
        "                \n",
        "            %cp gptransfer/results/out gptransfer/results/out_backup\n",
        "            avg_accuracy = sum(accuracies) / len(accuracies) + frozen_offset * .002\n",
        "            print(f'Average accuracy with {configs_string}: {avg_accuracy}\\n\\n')\n",
        "            printout(f'Average accuracy with {configs_string}: {avg_accuracy}\\n\\n')\n",
        "            return {'loss': -avg_accuracy, 'status': STATUS_OK}\n",
        "\n",
        "        best = fmin(objective, space, algo=tpe.suggest, trials=trials, max_evals=2000, show_progressbar=False)\n",
        "        pickle.dump(trials, open('gptransfer/results/trials.p', 'wb'))\n",
        "\n",
        "        print(accuracies)\n",
        "        \n",
        "if __name__=='__main__':\n",
        "    main()\n",
        "    \n",
        "# all_dropout False frozen_offset 0 lr 0.0001266190503028293 \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'loss': -0.9430999972820282, 'status': 'ok'}, {'loss': -0.9459499933719635, 'status': 'ok'}, {'status': 'new'}]\n",
            "2\n",
            "trial number 3\n",
            "all_dropout False frozen_offset 1 lr 3.0476704402180002e-05 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 6.29\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9353\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 5.97\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9314\n",
            "Average accuracy with all_dropout False frozen_offset 1 lr 3.0476704402180002e-05 : 0.935349996805191\n",
            "\n",
            "\n",
            "trial number 4\n",
            "all_dropout False frozen_offset 1 lr 0.000319395480145998 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 6.22\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9403\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 6.23\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9395\n",
            "Average accuracy with all_dropout False frozen_offset 1 lr 0.000319395480145998 : 0.9418999810218811\n",
            "\n",
            "\n",
            "trial number 5\n",
            "all_dropout False frozen_offset 0 lr 0.00022747933799086798 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 7.36\n",
            "elapsed minutes 0: 6.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9264\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 7.34\n",
            "elapsed minutes 0: 6.0\n",
            "Fold Complete\n",
            "Accuracy: 0.942\n",
            "Average accuracy with all_dropout False frozen_offset 0 lr 0.00022747933799086798 : 0.9341999888420105\n",
            "\n",
            "\n",
            "trial number 6\n",
            "all_dropout False frozen_offset 0 lr 0.0008058687009266354 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 7.36\n",
            "elapsed minutes 0: 6.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9159\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 7.36\n",
            "elapsed minutes 0: 6.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9292\n",
            "Average accuracy with all_dropout False frozen_offset 0 lr 0.0008058687009266354 : 0.9225499927997589\n",
            "\n",
            "\n",
            "trial number 7\n",
            "all_dropout False frozen_offset 2 lr 8.57218618155123e-05 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 5.13\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9363\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 5.13\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9336\n",
            "Average accuracy with all_dropout False frozen_offset 2 lr 8.57218618155123e-05 : 0.9389499940872192\n",
            "\n",
            "\n",
            "trial number 8\n",
            "all_dropout False frozen_offset 0 lr 4.952013121874927e-05 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 7.34\n",
            "elapsed minutes 0: 6.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9381\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 7.36\n",
            "elapsed minutes 0: 6.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9424\n",
            "Average accuracy with all_dropout False frozen_offset 0 lr 4.952013121874927e-05 : 0.9402499794960022\n",
            "\n",
            "\n",
            "trial number 9\n",
            "all_dropout False frozen_offset 1 lr 0.0005525606688006765 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 6.23\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9275\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 6.25\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.932\n",
            "Average accuracy with all_dropout False frozen_offset 1 lr 0.0005525606688006765 : 0.931749995470047\n",
            "\n",
            "\n",
            "trial number 10\n",
            "all_dropout False frozen_offset 2 lr 1.9233085226625196e-05 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 5.13\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9182\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "GPU GB used 0: 5.13\n",
            "elapsed minutes 0: 5.0\n",
            "Fold Complete\n",
            "Accuracy: 0.9298\n",
            "Average accuracy with all_dropout False frozen_offset 2 lr 1.9233085226625196e-05 : 0.9279999949932098\n",
            "\n",
            "\n",
            "trial number 11\n",
            "all_dropout False frozen_offset 0 lr 0.00023644878451271217 \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gpt-2/models/117M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SM8YNbPPMb9a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from hyperopt import Trials\n",
        "trials = pickle.load(open(\"gptransfer/results/trials.p\", \"rb\"))\n",
        "print(trials.trials[0]['result'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}